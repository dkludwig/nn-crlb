'''
Train neural network to invert a linear encoding.

The neural network we train to invert the 100x500
encoding matrix A (from "make_data.py") has
three fully-connected layers, the first with
50,000 sigmoid neurons, the second with 5,000,
and the last with 100 (output size). The training
minimizes the MSE on the 50,000 training vectors
generated by "make_data.py".

Hyperparameters:
- learning_rate = 0.3
- batch_size = 100
- momentum = 0.7

The learning rate of 0.3 was chosen with a good bit of
experimentation, but the batch size and momentum coefficient
were chosen basically heuristically. Training seems to
flatline around 7 epochs, but lower learning rates don't seem
to make a difference so it's kept at 0.3 for 10 epochs.

The full model is saved to a folder labeled "nn-inverse"
in the current directory
'''
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

def main():
    # load training and test data
    with np.load('nn-inverse-data.npz') as data:
        x_train = data['x_train']
        x_test = data['x_test']
        y_train = data['y_train']
        y_test = data['y_test']
        A = data['A']

    # initialize network architecture
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(50000, activation='sigmoid',
                              input_shape=(500,)),
        tf.keras.layers.Dense(5000, activation='sigmoid'),
        tf.keras.layers.Dense(100, activation='sigmoid')
    ])

    # set hyperparameters and loss function
    model.compile(tf.keras.optimizers.SGD(learning_rate=0.3, momentum=0.7),
                  loss=tf.keras.losses.MeanSquaredError())

    # train model
    history = model.fit(x_train, y_train,
                     validation_data=(x_test, y_test),
                     epochs=10, verbose=1, batch_size=100)

    # save model
    model.save('nn-fully-sigmoid')

    # plot loss history
    fig, axs = plt.subplots(1,2,figsize=(8,4))
    epochs = range(1, len(history.history['loss'])+1)

    axs[0].plot(epochs, history.history['loss'], label='loss')
    axs[0].plot(epochs, history.history['val_loss'], label='validation loss')
    axs[0].set_xlabel('Epochs')
    axs[0].set_ylabel('Mean Squared Error')
    axs[0].legend()

    axs[1].plot(epochs, history.history['loss'], label='loss')
    axs[1].plot(epochs, history.history['val_loss'], label='validation loss')
    axs[1].set_xlabel('Epochs')
    axs[1].set_yscale('log')
    axs[1].legend()

    plt.show()

if __name__ == '__main__':
    main()
